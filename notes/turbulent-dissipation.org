Notes on dissipation of energy in turbulent flows

* Points that still are not clear
- [ ] Can the intermittency increase the variance of the temperature fluctuations enough to explain t2?
- [ ] What is the role of shocks at macroscopic scales in the dissipation of kinetic energy?
  - Are we double-counting if we add this into the budget for t2?
- [ ] What is going on with the Taylor-scale Reynolds number Re_\lambda in the direct numerical simulations?
  - How is it that they can work with Re_\lambda = 1000 (implying Re = 1e6) and be able to numerically resolve from the integral scale down to the Kolmogorov scale?

* Summary of important points
- Turbulent energy dissipation, \varepsilon, is intermittent with extreme events dominating the dissipation
- The variance of \varepsilon increases markedly with Reynolds number, being of order \langle \epsilon^2 \rangle \approx 50 \langle\epsilon\rangle^2 for Re_\lambda = 1e4
  - Laboratory experiments suggest scaling as \langle\epsilon^{2}\rangle/\langle\epsilon\rangle^2 \sim Re_\lambda^{0.39} for Re_\lambda < 1e3
    - This is estimated from the kurtosis of the velocity gradients: K_(∂u/∂x) ≡ ⟨(∂u/∂x)^4⟩/⟨(∂u/∂x)^2⟩^2 = 15 \langle \epsilon^2 \rangle / 7 \langle \epsilon \rangle^2 (note K = 3 for a Gaussian distribution)
  - But there are arguments that the scaling should get steeper at higher Re_\lambda due to nested substructures in the flow
    - for sufficiently high Re_\lambda the "significant shear layers" themselves have a high Reynolds number and their own nested sub-layers
- For an H II region in thermal equilibrium, a small extra heating rate \epsilon in addition to the photoionization heating E will lead to a fractional temperature increase of t \equiv \delta T / T_0 = 0.36 \epsilon / E
  - The factor 0.36 is really 1/(a+b), where a = d ln \Lambda / d ln T and b = -d ln E / d ln T
  - This is assuming a = 2.3, and b = 0.5
  - This assumes that the turbulent heating timescale is short compared with the radiative cooling timescale
    - [ ] *need to check this* and think about what would happen in the opposite limit
    - On reflection, I think what we really need is that the interval between heating events is *short* compared with the cooling timescale
- Therefore, there is a linear relation between \langle \epsilon^2 \rangle and t^2 as it is classically defined.
  - t^2 \equiv \langle (\delta T)^2 \rangle / T_0^2 =
  - t^2 = 0.13 \langle \epsilon^2 \rangle / E^2 = 0.13 \langle\epsilon^{2}\rangle/\langle\epsilon\rangle^2  (\langle\epsilon\rangle/E)^2
  - The first term comes from the kurtosis
    - We will normalize at Re_\lambda = 1e3, since that is where the lab measurements seem to be reliable, K = 15 and beyond which there is some doubt about the power law index
    - So put K = 15 (Re_\lambda / 1e3)^\beta, where \beta = 0.39 for Gylfason or \approx 1 for Elsinga
    - So \langle\epsilon^{2}\rangle/\langle\epsilon\rangle^2 = 7 K / 15 = 7 (Re_\lambda / 1e3)^\beta
  - While the second term comes from
    - background turbulent dissipation rate \langle \epsilon \rangle = \rho v^3 / L, where L is the integral scale
    - photoelectric heating rate E = k T_* \alpha_B n^2
    - so that \langle\epsilon\rangle/E \approx (R_S/L) (T_0/T_*) (c_s/c) Ma^3 f / U
      - where R_S is the Stromgren radius, c_s is the sound speed, Ma is the Mach number, f is the filling factor, and U is the ionization parameter
      - [ ] /check over the above equation, which comes from the Apple Note/
    - From the Javier paper we find L = 1.44 r_0 (assuming m = 1) and r_0 \approx 0.02 D = 0.04 R_S, so R_S/L \approx 17.4
      - [X] /Modification to the Javier result?/ -- the above assumes that D = 2 R_S, but D is measured from a low isophote and includes a faint halo around the H II region. It might be better to use the fwhm of the brightness profile. But this would mean decreasing R_S/L, which we do not want to do. *Resolution: no change for now*
    - For regions ionized by O stars, typically T_0/T_* = 0.25
      - I should calculate the photoelectric heating rate explicitly from integrating the spectra in frequency
    - With c_s = 13 km/s, c_s/c = 4.34e-5
    - So \langle\epsilon\rangle/E \approx 1.89e-4 Ma^3 f / U
    - Ionization parameter is typically 0.02 and f \approx 1 for low to moderate luminosity regions
    - So \langle\epsilon\rangle/E \approx 9.45e-3 Ma^3
  - So, t^2 = 0.13 7 (Re_\lambda / 1e3)^\beta (9.45e-3 Ma^3)^2 = 8.13e-5 (Re_\lambda / 1e3)^\beta Ma^6
    - We really want this to get up to about 0.003 or higher for the low Mach number regions, so we really need Re_\lambda to be high

* Comparison of length and time scales
This is just a summary of results that are derived in more detail elsewhere in the notes.

- Proton gyroradius
- Collisional mean free path
- Ion-neutral collision scale
- Taylor microscale

* Definitions
** Ionization parameter
- Defined as U = F / c n, where F is the flux of ionizing photons and n is the number density of protons
- Relationship to radiation parameter, \Xi = P_rad/P_gas
  - \Xi / U = 15.8 (e_\star / f_euv) T_4^-1 = global value of 20 to 30 typically for H II regions ionized by early O stars (higher for late O or B stars)
  - See [[id:EE3830D5-75C8-41DE-AFA1-0B9130776009][Relationship between ionization parameter U and radiation parameter \Xi]]
- For a typical bright H II region, U \approx 0.02 and \Xi \approx 1
  - This is true for both the center of Orion Nebula and also for giant regions like 30 Dor
  - The Luminosities are 100 times larger in the latter, but the densities are 100 times smaller, so the ionization parameters are similar
  - For low-brightness regions, such as the EON, the densities are much lower (by a factor of about 100), so U is lower by factor of 5 or so
- We are interested in this here because we can calculate the Knudsen number and therefore the Reynolds number in terms of it
- Global value for an H II region
  - Although the density and (especially) flux will vary in the region, we can calculate a characteristic value using
    - F = Q / 4 \pi R_S^2
    - U = Q / 4 \pi R_S^2 c n
  - Then we use global ionization balance to eliminate one variable out of the set {Q, R_S, n, f}
    - Q = \alpha_B n_1^2 V
    - \alpha_B = 2.6e-13 cm^3/s
    - V = 4/3 \pi R_S^3 f
    - f is filling factor: fraction of volume occupied by dense gas (n = n_1), assuming the rest is effectively empty (n \ll n_1)
    - So Q = 4/3 \pi R_S^3 f \alpha_B n_1^2
    - f = Q / 4/3 \pi R_S^3 \alpha_B n_1^2 = 3100 Q_51 / R_pc^3 n_100^2
  - This gives alternative forms for U
    - U = (\alpha_B / 3 c) f n R
    - U = (1/c) (\alpha_B^2 / 36\pi)^(1/3) (f^2 Q n)^{1/3}
    - U = (1/c) (\alpha_B / 12\pi)^(1/2) (f Q / R)^{1/2}
    - U = (1/c) (1 / 4 \pi) (Q / R_S^2 n)
  - Putting in numbers (assuming \alpha_B = 2.6e-13 T_4^-0.8 cm^3/s)
    - U = 8.92e-4 f n_100 R_pc T_4^-0.8
    - U = 0.0130 (f^2 Q_51 n_100)^{1/3} T_4^-0.3
    - U = 0.0499 (f Q_51 / R_pc)^{1/2} T_4^-0.4
    - This is slightly different from what I derived last time
- It does depend on the filling factor of the ionized gas, but values of 0.02 are typical
*** Relationship between ionization parameter U and radiation parameter \Xi
:PROPERTIES:
:ID:       EE3830D5-75C8-41DE-AFA1-0B9130776009
:END:
- \Xi \equiv P_rad / P_gas = L / (4 \pi R^2 c (2 n k T))
- \Xi / U = L / Q 2 k T
  - L / Q \equiv k T'
    | Star |   L_4 |     Q_49 |    T' | \Xi / U T_4 |
    |------+------+---------+-------+-----------|
    | MS10 | 0.63 | 0.00013 | 1.3e8 |     6.5e3 |
    | MS20 | 5.45 |    0.16 | 9.4e5 |     4.7e1 |
    | MS40 | 22.2 |    1.41 | 4.4e5 |     2.2e1 |
    | BSG  | 30.2 |   0.016 | 5.2e7 |     2.6e3 |
   #+TBLFM: $4=$2 1e4 $lsun / $3 1e49 $k;s2::$5=$4  / 2 1e4;s2
    - At first it seemed weird that these values are so high (but this is now all resolved, see below)
    - For the cooler stars, f_euv is very low, which gives large ratios
  - For Orion, assuming Q=1e49, L=2e5 L_sun, we have T' = 5.5e5 K, \Xi / U = T' / 2 T = 32 (assuming T=8500 K)
- Alternative way of putting it:
  - Equivalent T of 1 Rydberg is 1.58e5 K
  - We can write L = L_fuv + L_euv = L f_fuv + Q \langle{}E\rangle_euv
    - where \langle{}E\rangle_euv is the average energy of an ionizing photon
    - f_fuv is fraction of bolometric luminosity emitted in the FUV and longer wavelengths
    - Probably clearer to write f_euv = 1 - f_fuv with f_euv the fraction of bolometric luminosity emitted in the EUV and shorter wavelengths
    - => L = Q \langle{}E\rangle_euv / f_euv
  - Also put \langle{}E\rangle_euv = e_\star k T_ryd where e_\star is the average ionizing photon energy in Rydbergs and T_ryd is the temperature equivalent to 1 Rydberg (1.58e5 K)
- So, getting back to the relation between radiation parameter and ionization parameter:
  - \Xi / U = L / Q 2 k T = (Q e_\star k T_ryd) / (f_euv Q 2 k T)
  - \Xi / U = (e_\star T_ryd) / (f_euv 2 T)
  - *\Xi / U = 15.8 (e_\star / f_euv) T_4^-1*
** Filling factor
- Relation to coefficient of variation of density s_n = \sigma_n / \langle n \rangle
  - f = 1 / (1 + s_n^2)
- Relation to shell thickness for spherical shell model
  - For a shell of relative thickness h = \Delta R / R, the filling factor is f = 1 - (1 - h)^3 = 3h - 3h^2 + h^3 \approx 3h for small h
- Observationally derived values for Orion
  - Peak density n_0 = 1e4 cm^-3
  - Flux of ionizing photons: F = Q / 4 \pi R^2 = 1e49 / (4 \pi (0.1 pc)^2) \approx 1e13 cm^-2 s^-1
  - Thickness H = F / \alpha_B n_0^2 = 1e13 / (2.6e-13 1e4**2) = 3.84615384615e17 cm =
  - Baldwin et al. (1991) find peak EM = 2.7e25 cm^-5 for the Orion nebula
    - EM = n^2 H f, so with n=1e4 and f=1, we have H = 2.7e17 cm, very similar
  - So, we have H \approx R, so filling factor is not very different from unity
    - The model has R_in = 0.1 pc = 3.086e17 (they rely just fix the ionizing flux, so this depends on an assumption about the ionizing luminosity of 1e49) and thickness of 2.5e17 cm
    - Do the relative thickness is h = 2.5 / (3.086 + 2.5) = 0.448, so f = 0.83
  - Alternatively, we can derive it from the coefficient of variation of density
    - s_n = 0.66, so f = 1 / (1 + 0.66^2) = 0.7 - not very different
  - Baldwin also find an ionization parameter for the illuminated face of U = 10**-1.48 = 0.033
** Reynolds number, Re
:PROPERTIES:
:ID:       ED1F0BA1-549F-4117-92EA-9CCEF82DBBB5
:END:
- Ratio of inertial to viscous forces
- Re = u L / \nu
  - u is the characteristic velocity
    - In our case, we will write it as Ma c_s, where c_s is the isothermal sound speed and Ma is the rms Mach number of turbulent velocity fluctuations (we could maybe include the ordered bulk motions too, which would put a floor of Ma \approx 1, even for the low luminosity regions)
  - L is the characteristic length scale (e.g. the size of the region, or the integral scale of the velocity fluctuations)
  - \nu is the kinematic viscosity
    - \nu = \lambda_mfp u_therm
    - for electrons u_therm \approx 550 T_4^{1/2} km/s \approx (m_p/m_e)^{1/2} c_s
    - \lambda_mfp \approx 2.625e5 T_e^2 n_e^-1 (ln \Lambda)^-1 cm
      - ln \Lambda = 9.452 + 1.5 ln T_e - 0.5 ln n_e \approx 19
      - \lambda_mfp \approx 1.38e12 T_4^2 n_e^-1 cm
   
*** Earlier incorrect calculation
- From the calculation in [[id:FDD9A1A6-53E0-4220-AF9E-3EBB899CEF95][Knudsen number, Kn]] we find typically Re = 1e14 for H II regions
  - Very big!
  - Although, in my notes from 2021 [[id:F94CE6C5-5508-4F5D-BC24-482A5636C168][Reynolds number in H II regions]] I get a much smaller number - need to reconcile these
  - One of the differences is that I used the electron velocity to derive the kinematic viscosity
- Although that is for the scale of the Stromgren Radius. The outer scale of the turbulence may be 50 times smaller, which would give a Re of 2e12, but that is still big
** Knudsen number, Kn
:PROPERTIES:
:ID:       FDD9A1A6-53E0-4220-AF9E-3EBB899CEF95
:END:
- Ratio of mean free path to characteristic length
- In my will-ckk draft from 2015, I estimate Kn for H II regions and find it proportional to 1/U where U is the ionization parameter. 
  - Kn = 3.76e-12 U^-1
  - Where U = 0.001 to 0.01 typically for H II regions
    - [ ] Note that this needs to be modified by the effect of filling factor
  - So Kn = 1e-10 +/- 0.5 dex
- From the Wikipedia page, there is a relation between Kn, Ma, and Re
  - But this assumes that the particle mass is the same in the viscosity and the sound speed, which is not correct for us since it is electrons that dominate the viscosity, but ions that give the sound speed
  - For isothermal Mach number, it is Kn = sqrt(pi/2) Ma/Re = 1.253 Ma/Re
  - 
- So for transonic turbulence (Ma = 1), we have Re = 1.253/Kn
** Magnetized or not?
- Although the low Kn means we are collisionally on the large scales, we still need to check whether the small scales are magnetic or non-magnetic
- In the first case, we will have important non-collisional gyro-viscosity effects that isotropise the velocity distribution without really thermalising it
- Non-magnetic requires \Omega_i \tau_i, \Omega_e \tau_e \ll 1 where \Omega is the gyrofrequency and \tau is the collision time
  - See https://farside.ph.utexas.edu/teaching/plasma/Plasma/node53.html
- So this is really important. I think the condition will be easily satisfied in H II regions
  - 
- But one thing I am still not clear on is what the importance of magnetic field is in H II regions if we assume that
  1. They are not very important on the large scales, assuming the v_A is roughly constant in the ISM (as suggested from David and Sundar's work for instance), since \beta = 2 c_s^2 / v_A^2. So if v_A = 3 km/s and c_s = 10 km/s, then \beta \approx 20
  2. They are not important on small scales because
     - electron Larmor radius is 10^5 cm for B = 10^-4 G
** Taylor microscale, \lambda
- Supposedly the scale below which viscosity starts to have an effect - *not true* for very high Reynolds numbers
- From Pope, eq. 6.64, Taylor-scale Reynolds number is
  - R_\lambda = ((20/3) Re_L)^{1/2}
  - Re_L = 1e8 => R_\lambda = 2.6e4
- \lambda / L = sqrt(10) Re^(-1/2)
- For Re = 2e12, \lambda = 2.2e-6 L
  - This means that the Reynolds number at the Taylor scale is 2e12 2.2e-6 = 4,400,000
  - Still very big!!
- This is still much smaller than we could ever see in an H II region
  - In Orion, L = 2 r_0 = 0.14 pc, so \lambda = 3e-7 pc = 6e13 cm = 0.06 AU
  - In 30 Dor, L = 8 pc, so \lambda = 3.6 AU
- Mean velocities at the Taylor scale, assuming M = 1 @ L and V ~ r^{m/2}
  - m = 1 : V = 0.015 km/s
  - m = 2/3 : V = 0.13 km/s

    
** Kolmogorov scale, \eta
- The scale below which viscosity dominates
- \eta / L = Re^(-3/4) = 2e12^(-3/4) = 6e-10
  - Orion: \eta = 2600 km
  - 30 Dor: \eta = 0.001 au = 0.2 Rsun



** Large-eddy simulations
- In the (compressible) turbulence literature, what are called Direct Numerical Simulations (DNS) are simulations that resolve all scales of the turbulence down to the dissipation scale. This is only possible for relatively low Reynolds numbers, so is not at all possible for any astrophysical contexts.
- Instead, Large-Eddy Simulations (LES) are used, where the large scales are resolved, but the small scales are modelled. This is done by filtering the Navier-Stokes equations to remove the small scales, and then adding a subgrid-scale model to account for the effects of the small scales on the large scales.
- This is discussed in detail in Pope, Chapter 13, where he spends a lot of time discussing the traditional approach:
  - in which the small scales are explicitly filtered out on a scale \Delta, which should be smaller than the smallest energy-containing scales.
    - For homogeneous isotropic turbulence and for free-shear flows, this is about 10 times less than the integral scale, which is really large. They talk about doing simulations with 40^3 grid cells, which is wild!
    - For wall-bounded flow, it seems the energy-containing scales are much smaller
      : the size of the important near-wall motions scales with the viscous lengthscale δν (which decreases with the Reynolds number relative to the flow lengthscale δ).
      As a result, people do LES with near-wall modelling (LES-NWM), but this would not seem to be a concern for astrophysical flows (except maybe over asteroids, etc ...)
  - But then the numerical grid cells are chosen to be significantly smaller than \Delta so that the filtered equations can be solved to high accuracy on the grid without any influence of the effective grid viscosity.
  - The residual motions on scales smaller than \Delta are then modelled using for example an eddy-viscosity model. The simplest of these is the Smagorinsky model, which is a mixing length that is a fixed fraction of the filter scale \Delta.
- However, he also talks about a competing point of view, which I think is what is done nearly always in the astrophysical simulations. From p. 632:
  : The opposite viewpoint, advocated by Boris et al. (1992), is that no explicit filtering should be performed and no explicit residual stress model should be used (τ^r_ij = 0). Instead, an appropriate numerical method is used to attempt to solve the Navier–Stokes equations for \overbar{U}. Because the grid is not fine enough to resolve the solution to the Navier–Stokes equations, significant numerical stresses τ^h_ij arise. Thus, filtering and residual-stress modelling are performed implicitly by the numerical method.
  - Advantages of this approach:
    : (for a given grid size) as much as possible of the turbulent motion is represented explicitly by the LES velocity field U(x,t), and that energy is removed from U only where and when it is necessary to do so. It is argued that the details of how energy is removed are unimportant, just so long as there is a mechanism to remove energy from the smallest resolved scales without contaminating the larger scales. (This is similar to the argument used to justify the use of residual-stress models that perform poorly in a priori tests.) A further advantage is that the time and effort required to develop and test a residual-stress model are eliminated.
  - Primary disadvantage
    : the modelling and the numerics are inseparably coupled. Sometimes the approach is referred to as ‘no model,’ but it should be appreciated that this is an inadequate description: for a given flow the simulation results depend both on the numerical method and on the grid used. It is not possible to refine the grid to obtain grid-independent solutions (short of performing DNS). Another disadvantage is that there is no representation or estimation of the subgrid-scale motions that can be used for defiltering or in models for other subgrid-scale processes.


** Neutral damping scale
:PROPERTIES:
:ID:       A739C76C-F8E7-46C9-A04F-CB943B249FD5
:END:

** Magnetic effects

* Turbulent dissipation rate

** Relevant papers

*** Elsinga et al 2020
Title: /Extreme dissipation and intermittency in turbulence at very high Reynolds numbers/

: For homogeneous isotropic turbulence, the dissipation variance is directly related to the flatness factor of the longitudinal velocity gradient [19,20], which increases with Reynolds number [15,17,20].

Also

: Presently, there is no suitable theory to explain the observed Reynolds number dependence of the dissipation PDF, its variance and also its extremes.

Should note that they are only doing incompressible turbulence

They find that the mean-square dissipation divided by square of the mean dissipation increases significantly with Reynolds number. This is what should create the temperature fluctuations.

They calculate this from a quantity called F
: the flatness, F, of the longitudinal velocity gradient
which is defined as the ratio of the fourth moment to the square of the second moment of the longitudinal velocity gradient.

This is related to the dissipation rate by
: F = 15 \langle \epsilon^2 \rangle / 7 \langle \epsilon \rangle^2
and they say that
: the normalized dissipation variance is given by ((7/15) 𝐹 − 1)
where the "-1" comes from Var(\epsilon) \equiv \langle \epsilon^2 \rangle - \langle \epsilon \rangle^2, so normalized variance is  Var(\epsilon)/\langle \epsilon \rangle^2 = (\langle \epsilon^2 \rangle / \langle \epsilon \rangle) - 1

This does not matter since F \approx 100 for Re_\lambda = 1e4, which is the sort of regime we are interested in. Note that Re_\lambda is the Taylor scale Reynolds number, which is of order the square-root of the integral-scale Reynolds number.

They show their own model prediction and a single power-law from Gylfason et al 2004 ([[id:05430AD7-562A-4CD8-AFBB-A6FB1F603454][see below]]). These both fit the observational data equally well, but they diverge significantly at high Re_\lambda, with the current paper predicting much higher values from the increasing power more slope as the nested sub-structures ans sub-sub-structures are added.



**** Citations of Elsinga et al 2020
Some of these may warrant their own dedicated sections.

- Elsinga et al. 2022. /Intermittency across Reynolds numbers – the influence of large-scale shear layers on the scaling of the enstrophy and dissipation in homogenous isotropic turbulence/ extends the previous paper to include enstrophy (whatever that is!) and refines their model for the energy dissipation
- Chen 2023. /New features in turbulence dissipation/ mainly concerned with shock-turbulence interactions, so this would extend the Elsinga results to compressible turbulence - maybe. Mentions role of dilatational dissipation in compresible turbulence. 
- D. A. Donzis and J. P. John, /Universality and scaling in homogeneous compressible turbulence/, Phys. Rev. Fluids 5, 084609 (2020). Cited by Chen
- K. Yamamoto, T. Ishida, T. Watanabe, and K. Naga ta, /Experimental and numerical investigation of compressibility effects on velocity derivative flatness in turbulence/, Phys. Fluids 34, 055101 (2022). Cited by Chen. Finds that *flatness increases with Mach number*, which is just what we need to increase the temperature fluctuation. Now has its [[id:A8E809DE-57D1-4A22-ADD1-9A40A0CE25EB][own section]]

*** Yamamoto et al. 2022
:PROPERTIES:
:ID:       A8E809DE-57D1-4A22-ADD1-9A40A0CE25EB
:END:
Title: /Experimental and numerical investigation of compressibility effects on velocity derivative flatness in turbulence/

Abstract:
: Compressibility effects on the velocity derivative flatness F_{\partial{}u\prime/\partial{}x} are investigated by experiments with opposing arrays of piston-driven synthetic jet actuators (PSJAs) and direct numerical simulations (DNS) of statistically steady compressible isotropic turbulence and temporally evolving turbulent planar jets with subsonic or supersonic jet velocities. Experiments using particle image velocimetry show that nearly homogeneous isotropic turbulence is generated at the center of a closed box from interactions between supersonic synthetic jets. The depen- dencies of F_{\partial{}u\prime/\partial{}x} on the turbulent Reynolds number Re_\lambda and the turbulent Mach number M_T are examined both experimentally and using DNS. Previous studies of incompressible turbulence indicate a universal relationship between F_{\partial{}u\prime/\partial{}x} and Re_\lambda. However, both experiments and DNS confirm that F_{\partial{}u\prime/\partial{}x} increases relative to the incompressible turbulence via compressibility effects. Although F_{\partial{}u\prime/\partial{}x} tends to be larger with M_T in each flow, the F_{\partial{}u\prime/\partial{}x} in the turbulent jets and the turbulence generated from PSJAs deviate from those in incompressible turbulence at lower M_T compared with isotropic turbulence sustained by a solenoidal forcing. The PSJAs and supersonic planar jets generate strong pressure waves, and the wave propagation can cause an increased F_{\partial{}u\prime/\partial{}x}, even at low M_T. These results suggest that the compressibility effects on F_{\partial{}u\prime/\partial{}x} are not solely determined from a local value of M_T and depend on the turbulence generation process.

Introduction talks about "turbulence chambers", in which compressible turbulence can be studied. These work by having lots of piston-driven synthetic jet actuators (PSJAs) firing off into the chamber. It has the advantage that the mean velocity is low in the center of the chamber, unlike in wind tunnels (where the turbulent velocity is a small fraction of the bulk velocity).
: Opposing arrays of PSJAs can generate statistically steady and nearly homogeneous isotropic turbulence with a small mean velocity at the chamber center. 
/This is great, because it is the same with turbulence in H II regions, where the turbulent velocities and the bulk velocities are similar/
: The employment of PSJAs extends the velocity range of turbulence chambers from subsonic to transonic and even super- sonic regimes. Furthermore, the ability of PSJAs to generate statisti- cally steady turbulence helps evaluate flow statistics and take measurements for a long time without limitations from the time dura- tion of the facility.
They are mainly interested in investigating whether the universality hypothesis holds, or whether the large-scale flow has an influence on the small scale turbulent dissipation. 

- They have an integral scale Reynolds number of 900
- The chamber size is about 10 cm, with integral scale being about 5 times less than that
- The jets are fired with a frequency of 150 Hz, maximum jet Mach number of about 1.2 in blowing phase and subsonic in sucking phase
- Kolmogorov scale is about 0.06 mm
- Dilatation \theta is defined as \theta = \nabla \cdot u and they define highly compressive regions as those with \theta < - 5 \theta_{rms}
- They do DNS of both isotropic turbulence and planar jets, with Reynolds numbers from a few hundred to 14,000 and Mach numbers from 0.6 to 2.6. The grid sizes are about 1000 cubed, which they say is good enough to resolve the Kolmogorov scale.
- For the experiment, their turbulent Mach numbers are only M_T \approx 0.02 with u_rms about 5 m/s and mean velocities about 1 m/s
- Taylor microscale \lambda_x \equiv u_rms / (du/dx)_rms defines the Taylor-scale Reynolds number Re_\lambda = u_rms \lambda_x / \nu
  - They estimate Re_\lambda = 383 and 932 for their two experiments
- For two different scenarios, isotropic turbulence with Re_L0 = 900 and planar jets, they estimate that Re_\lambda \approx 100
  - which would give flatness F \approx 6 for incompresible turbulence
    - for instance the equation in [[id:05430AD7-562A-4CD8-AFBB-A6FB1F603454][Gylfason et al 2004]] gives 100**0.39 = 6.02
  - but they find much larger flatness, up to 20 for M_T = 0.9 in the isotropic turbulence
- They also find a negative skew in the the probability distribution of pressure–dilatation correlation: \Pi_D = P \partial u_i/\partial x_i, which increases as F increases
- Their jet experiments also get to F \approx 20, but this is for a larger Reynolds number of 900 and a much smaller turbulent Mach number of M_T \approx 0.03
  - The incompressible equation would give F = 14, although their data have about 8
  - So this is a modest increase of about 2, even at such a low Mach number
- They point out that the conditions of the driving seem to have an effect on the scaling of flatness with turbulent Mach number, with the deviations from the incompressible case starting at smaller M_T when the turbulence is caused by a faster flow, such as jets. 
*** Johnson & Wilczek 2023
:PROPERTIES:
:ATTACH_DIR: /Users/will/Dropbox/turb-t2-paper/notes/turbulent-dissipation_att
:ID:       935028F2-A5A8-4890-8367-E49AE5AB4284
:END:
Title: /Multiscale Velocity Gradients in Turbulence/
Annual Review of Fluid Mechanics, Volume 56, pp. 463-490

A great review paper all about the velocity gradient tensor (VGT), A_ij \equiv du_i/dx_j. It is focused entirely on the incompressible case, for which the VGT has two invariants: Q and R (invariants meaning scalars that are independent of the coordinate system).

/In other papers, there is discussion of the first invariant P, which is the negative of the trace of the VGT, which is always zero in the incompressible case, but is the dilatation (divergence) in the compressible case, with P > 0 signifying compression/

: Q expresses the balance of enstrophy and strain-rate-squared magnitude
[[file:turbulent-dissipation_att/screenshot-20241023-084741.png]]
: R expresses the balance between enstrophy production (vortex stretching) and dissipation production (strain self-amplification)

This follows from an earlier decomposition of the VGT into symmetric part S_ij and antisymmetric part W_ij, where S_ij = 1/2 (du_i/dx_j + du_j/dx_i) and W_ij = 1/2 (du_i/dx_j - du_j/dx_i) (with implied summation over repeated indices). The antisymmetric part is related to the vorticity pseudo-vector: W_ij = -1/2 \epsilon_{ijk} \omega_k, where \epsilon_{ijk} is the Levi-Civita symbol, so the enstropy is \omega^2 = -2 W_ij W_ij.

Averaged over volume of a homogeneous flow, both Q and R are zero (because can be written as divergence of a vector).

: In particular, ⟨Q⟩ = 0 has the consequence that average enstrophy is equal to the average strain-rate-squared magnitude, and ⟨R⟩ = 0 means that average strain production is directly proportional to average enstrophy production. One consequence is that the net (local and nonlocal) effect of vortex stretching is to enhance the global dissipation rate (Carbone & Bragg 2020), even though it locally decreases it (as a sink in Equation 8) (Tsinober 2009).

Large positive Q is means high enstrophy, occurs in localised structures, associated with slight negative R. /I had thought these might be vortex tubes, but based on Thacker et al 2023, they might be sheets/

Large negative Q means high squared strain, which seems to be localised around the borders of the high-enstropy structures, associated with large positive R. This is where the dissipation is happening. It is an attractor in the phase space of the VGT. Meaning that fluid elements from a variety of initial conditions tend to evolve towards it. /Actually, this is misleading. I had been looking at streamlines of the restricted Euler system, which neglects the viscosity and non-local pressure effects. When those are included, then the phase space trajectories are loops in the Q-R plane. See Baj 2024/

*** Baj 2024
Title: /The topology-conditioned turbulence kinetic energy budget/

Analyses experiments and DNS simulations with Re_\lambda of 200 to 400.

Looping period in the Q-R plane is about 30 to 40 times the Kolmogorov timescale, with a slight negative dependence on the initial Q: Q_0^-0.15

/I need to work out if this is approximately the eddy turnover time at the Taylor scale/




*** Gylfason et al 2004
:PROPERTIES:
:ID:       05430AD7-562A-4CD8-AFBB-A6FB1F603454
:END:
Title: /Intermittency, pressure and acceleration statistics from hot-wire measurements in wind-tunnel turbulence/

An empirical study, aimed at measuring
- mean-squared pressure gradient, χ
- normalized acceleration variance, a_0
  
They calculate the flatness, which they call the
: derivative kurtosis, K_(∂u/∂x) ≡ ⟨(∂u/∂x)^4⟩/⟨(∂u/∂x)^2⟩^2
(the definition is exactly the same as F in Elsinga).

They find that a single power law fits their observational data adequately well on the range 100 \le R_λ \le 900:
: K_∂u/∂x ∼ R_\lambda^0.39

They have an alternative way of specifying the Taylor microscale:
: \lambda =[ U^2 ⟨u^2⟩ / ⟨(∂u/∂t)^2⟩ ]^(1/2)

  

*** Cho & Lazarian 2003
Title: /Compressible Magnetohydrodynamic Turbulence: Mode Coupling, Scaling Relations, Anisotropy, Eddy Energetics, and Intermittency/

Has direct simulations of compressible MHD turbulence in a box, with a variety of sonic and Alfvenic Mach numbers. They include low-beta and high-beta cases (the latter are more relevant to us, since we expect the magnetic pressure to be sub-dominant in H II regions).

They mention that even in high-beta plasmas (magnetic pressure unimportant at the large scales), that because the turbulent velocity fluctuations decrease with scale, then at small enough scales the magnetic pressure will become important.
- /My comments on this:/ this is all very well, but
  1. [ ] The magnetic pressure is still smaller than the thermal pressure. I guess that the thermal pressure /fluctuations/ are smaller though, so they will be affected by the anisotropy of the magnetic field.
  2. [ ] Also, how to reconcile with the claims of the Elsinga 2020 paper that for high Reynolds numbers the velocity differences across the "significant shear layers" are of order the mean velocity?



*** Goldreich & Sridhar 1995
Title: /Toward a theory of interstellar turbulence. 2: Strong Alfvenic turbulence/

This is still in the incompressible regime, but builds on a previous paper, which treated weak Alfven turbulence.

They find that "eddies" (scare quotes are theirs) are elongated along the magnetic fields lines, increasingly so at smaller scales:
- k_z / k_\perp = (L k_\perp)^{-1/3}

*** Lithwick & Goldreich 2001
Title: /COMPRESSIBLE MAGNETOHYDRODYNAMIC TURBULENCE IN INTERSTELLAR PLASMAS/
This paper is referred to a lot in the Cho & Lazarian paper.

Mentions that [[id:A739C76C-F8E7-46C9-A04F-CB943B249FD5][neutral damping]] scale will give a lower limit to the scale of density fluctuations.

From their abstract, their most important results:

: 1. Density fluctuations are due to the slow mode and the entropy mode. Both modes are passively mixed by the cascade of shear Alfvén waves. Since the shear Alfvén waves have a Kolmogorov spectrum, so do the density fluctuations.

: 2. Observed density fluctuation amplitudes constrain the nature of MHD turbulence in the interstellar medium. Slow mode density fluctuations are suppressed when the magnetic pressure is less than the gas pressure. Entropy mode density fluctuations are suppressed by cooling when the cascade timescale is longer than the cooling timescale. These constraints imply either that the magnetic and gas pressures are comparable or that the outer scale of the turbulence is very small.

- [ ] I need to study this argument in more detail
  - because at the moment, the cooling part does not make sense to me.
    - I suppose that in the isothermal case there is no entropy-mode cascade?
  - And the slow mode being suppressed at high beta is also something I need to understand better
    - Which mode is it that devolves into sound waves in the non-magnetic case
: 3. A high degree of ionization is required for the cascade to survive damping by neutrals and thereby to extend to small length scales. Regions that are insufficiently ionized produce density fluctuations only on length scales larger than the neutral damping scale. These regions may account for the excess of power that is found on large scales.

: 4. Provided that the thermal pressure exceeds the magnetic pressure, both the entropy mode and the slow mode are damped on length scales below that at which protons can diffuse across an eddy during the eddyÏs turnover time. Consequently, eddies whose extents along the magnetic field are smaller than the proton collisional mean free path do not contribute to the density spectrum. However, in MHD turbulence eddies are highly elongated along the magnetic field. From an observational perspective, the relevant length scale is that transverse to the magnetic field. Thus, the cutoff length scale for density fluctuations is significantly smaller than the proton mean free path.

: 5. The Alfvén mode is critically damped at the transverse length scale of the proton gyroradius and thus cascades to smaller length scales than either the slow mode or the entropy mode.

**** More detail on the entropy mode and slow mode
: Density fluctuations that obey the Kolmogorov scaling occur in homogeneous subsonic hydrodynamic turbulence. They are due to the entropy mode, a zero-frequency isobaric mode whose density fluctuations are offset by temperature fluctuations.

So this cannot work in an isothermal medium, because the temperature fluctuations are not allowed. Does this really mean that we do not have the entropy mode? And what can replace it for causing density fluctuations in an isothermal medium?

I think the answer might be given in the [[id:38E70922-87BD-4127-8A02-010B76484E30][next section]]

**** Footnote on r^{2/3} scaling of density fluctuations
:PROPERTIES:
:ID:       38E70922-87BD-4127-8A02-010B76484E30
:END:
: 1 Density fluctuations due to the Reynolds stress scale as
: \lambda^{2/3}. In addition, the dissipation of turbulent kinetic
: energy yields entropy fluctuations. The ratio of the corresponding
: density fluctuations to the mean density is comparable to the square
: of the Mach number at the length scale of interest ; hence, these
: density fluctuations are also proportional to \lambda^{2/3}.

That is interesting that the density fluctuations are proportional to M^2, and so are steeper than the velocity fluctuations. Remember that this is in the incompressible regime.

I think that these "entropy fluctuations" from the dissipation of turbulent kinetic energy are different from the entropy mode mentioned above, and these would still be present in the isothermal case. 
*** Goldreich & Sridhar 2006
Title: /FOLDED FIELDS AS THE SOURCE OF EXTREME RADIO-WAVE SCATTERING IN THE GALACTIC CENTER/

This paper is the first to walk back the idea that pulsar scintillation requires large-amplitude density fluctuations at very small scales in the ISM. Instead the propose folded magnetic sheets, an idea that is developed much more fully by Ue-Li Pen.

They talk of turbulent heating rates in terms of timescales. And compare them with the radiative cooling timescale
*** Stanimirovic & Zweibel 2018
Title: /Atomic and Ionized Microstructures in the Diffuse Interstellar Medium/

Annual Reviews paper that gives a good overview of the observational evidence for microstructures and a bit on the theory of them.
*** Coburn et al 2022
Title: /A measurement of the effective mean free path of solar wind protons/

Abstract
: Weakly collisional plasmas are subject to nonlinear relaxation processes, which can operate at rates much faster than the particle collision frequencies. This causes the plasma to respond like a magnetised fluid despite having long particle mean free paths. In this Letter the effective collisional mechanisms are modelled in the plasma kinetic equation to produce density, pressure and magnetic-field responses to compare with spacecraft measurements of the solar wind compressive fluctuations at 1 AU. This enables a measurement of the effective mean free path of the solar wind protons, found to be ≈4 × 10^5 km, which is approximately 10^3 times shorter than the collisional mean free path. These measurements are shown to support the effective fluid behaviour of the solar wind at scales above the proton gyroradius and demonstrate that effective collision processes alter the thermodynamics and transport of weakly collisional plasmas.

Contains a useful discussion of different regimes of collisional and non-collisional plasmas, with lots of references.

This is more relevant to the shocked stellar wind bubbles in H II regions, rather than the H II region itself (which is collisional). 
*** Beattie et al. 2024
Title: /Magnetized compressible turbulence with a fluctuation dynamo and Reynolds numbers over a million/

Has a 10080^3 supersonic MHD simulation (M = 4).

Very nice visualization in their Fig 1

: 2.1 The world’s largest supersonic MHD turbulence simulation:
:
: We present the first results from an ensemble of driven, supersonic, δu/cs = 4.3 ± 0.2, magnetized turbulence simulations that have a magnetic field being self-consistently maintained by the turbulent dynamo in saturation, providing a volume integral energy ratio of Emag/Ekin = 0.242 ± 0.022. The grids vary from 2520^3 (Rm ∼ Re ∼ 105) up to 10080^3 (Rm ∼ Re ∼ 3 × 106), discretised on a triply-periodic domain with length L. Presently, these are the largest supersonic, magnetized simulations in the world, almost an order of magnitude larger in grid resolution (and Reynolds numbers) compared to previous simulations in this regime (Fielding et al., 2023; Grete et al., 2023) and are the first simulations to resolve both a supersonic and subsonic cascade with a self-consistently maintained magnetic field. The simulations utilised over 80 million CPU hours distributed across nearly 140,000 compute cores on the high-performance supercomputer, SuperMUC-NG, at the Leibniz Supercomputing Centre. We integrate the 10080^3 simulation for t ≈ 2t0, where t0 = l0/δu is the turnover time on the driving scale of the turbulence l0 = L/2 (or equivalently kL/2π = 2), allowing for time-averaging of all key statistics across ≈ 2t0, making for robust, statistically significant results. We provide details on the simulation methods in 4.
*** Ha et al 2024
Title: /MACHINE-LEARNING CHARACTERIZATION OF INTERMITTENCY IN PLASMA TURBULENCE: SINGLE AND DOUBLE SHEET STRUCTURES/

This uses PIC simulations, so probably on much smaller scale than what we are interested in. And non-collisional I imagine.

*** Ocker et al 2024a
Title: /Implications for Galactic Electron Density Structure from Pulsar Sightlines Intersecting HII Regions/

Has a bizarre complicated cloudlet mode for H II regions that has 3 different density variation parameters.
- [ ] Refers to some earlier papers, which I should check out
- They do seem to have anticipated my f = 1 / (1 + s^2) result, where s is the coefficient of variation, stddev / mean. 

*** Ocker et al 2024b
Title: /Pulsar scintillation through thick and thin: bow shocks, bubbles, and the broader interstellar medium/ 
- By bow shocks, they mean pulsar bow shocks, so it is not of such interest as I had first thought.


* Other factors
In case the intermittent turbulent dissipation is not enough to reproduce the observed t^2, here are some additional factors that might help:

** Compressibility
- Nearly all of the theoretical and experimental work is done on incompressible turbulence, but we have RMS Mach numbers from 0.5 to 1.5, and even higher for the most luminous regions. How this affects the Reynolds number scaling of the dissipation rate is unknown. 

** Isothermality and the Bernoulli entropy ratchet
- The fact that we have an efficient photo-electric heating mechanism means that we can maintain an isothermal equation of state in the compressible turbulent cascade, so long as the dynamic time remains longer than the heating time.
- I think this means that we extract energy from the radiation field, via repeated isothermal expansions (entropy conserving) and shock compressions (entropy increasing), which increase the Bernoulli constant of the gas.
  - Expansion satisfy 0.5 v^2 + c_s^2 ln  \rho = b_0
  - Shocks satisfy \rho_2 = M^2 \rho_1; v_2 = v_1 / M^2
  - So we can imagine a cycle
    - Start with \rho_0, v_0 = 0
    - Accelerate to v_1 = M c_s
      - c_s^2 ln \rho_0 = b_0 = c_s^2 ln \rho_1 + 0.5 M^2 c_s^2
      - => \rho_1 = \rho_0 exp(-0.5 M^2)
    - Now have a perpendicular shock of strength M
      - \rho_2 = \rho_1 M^2 = \rho_0 exp(-0.5 M^2) M^2
      - v_2 = v_1 / M^2 = c_s / M
      - b_2 = 0.5 v_2^2 + c_s^2 ln \rho_2
        = 0.5 c_s^2 / M^2 + c_s^2 ln [\rho_0 exp(-0.5 M^2) M^2]
        = c_s^2 { 0.5/M^2 + ln \rho_0 - 0.5 M^2 + ln M^2 }
    - Put M = 1 + m with m \ll 1
      - 1/M^2 = 1 - 2m + 3m^2 - 4m^3 + 5m^4 + ...
      - M^2 = 1 + 2m + m^2
      - ln M^2 = 2m - m^2 + (2/3) m^3 - (1/2) m^4 + ...
    - b_2/c_s^2 = ln \rho_0 + 0.5 (1 - 2m + 3m^2 - 4m^3 + 5m^4) - 0.5 (1 + 2m + m^2) + 2m - m^2 + (2/3) m^3 - (1/2) m^4
      - constant term: ln \rho_0 + 0.5 - 0.5 = ln \rho_0
      - m term: -1 - 1 + 2 = 0
      - m^2 term: 1.5 - 0.5 - 1 = 0
      - m^3 term: -2 + 0 + 2/3 = -4/3
      - m^4 term: 2.5 - 0 - 0.5 = 2a
  - So this actually decreases the Bernoulli constant, which is not what I wanted
    - To leading order, b_2 = b_0 - (4/3) m^3 for M = 1 + m
- The whole idea is misconceived because the Bernoulli law only applies to steady-state flow, which makes absolutely no sense in a turbulent cascade.

** Direct heating through shocks

* See also
- [[file:../../mariano-velocity-statistics/mariano-velocity-statistics.org][Notes from Javier project from 2021]]
- 
